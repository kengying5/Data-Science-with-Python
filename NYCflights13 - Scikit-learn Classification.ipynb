{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import sklearn\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import linear_model, cross_validation, metrics, svm, ensemble\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.cross_validation  import train_test_split, cross_val_score, ShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 9,5\n",
    "sb.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.read_csv(\"C:\\Users\\Sim Keng Ying\\Desktop/nycflights13_flights.csv\")\n",
    "weather = pd.read_csv(\"C:\\Users\\Sim Keng Ying\\Desktop/nycflights13_weather.csv\")\n",
    "airports = pd.read_csv(\"C:\\Users\\Sim Keng Ying\\Desktop/nycflights13_airport.csv\")\n",
    "\n",
    "df_with_weather = pd.merge(flights, weather, how='left', on=['year','month', 'day', 'hour'])\n",
    "df_overall = pd.merge(df_with_weather, airports, how='left', left_on='dest', right_on='faa')\n",
    "df_overall = df_overall.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using logistic regression to determine whether flights are delayed or non-delayed, where delayed will be at least 15min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = 'dep_delay'\n",
    "features =  ['month','day','dep_time','arr_time','carrier','dest','air_time','distance', \n",
    "             'lat', 'lon', 'alt',  'dewp', 'humid', 'wind_speed', 'wind_gust', \n",
    "             'precip', 'pressure', 'visib' ]\n",
    "\n",
    "features_v = df_overall[features]\n",
    "pred_v = df_overall[pred]\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "features_v['carrier'] = pd.factorize(features_v['carrier'])[0]\n",
    "features_v['dest'] = pd.factorize(features_v['dest'])[0]\n",
    "\n",
    "#setting delayed as 15min\n",
    "how_late_is_late = 15.0\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features_v = scaler.fit_transform(features_v)\n",
    "\n",
    "features_train, features_test, pred_train, pred_test = train_test_split(\n",
    "    scaled_features_v, pred_v, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr = sklearn.linear_model.LogisticRegression()                                                 \n",
    "logistic_fit=clf_lr.fit(features_train, \n",
    "                        np.where(pred_train >= how_late_is_late,1,0))\n",
    "\n",
    "predictions = clf_lr.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "       0     1\n",
      "0  48403  1243\n",
      "1  12569  2171\n",
      "\n",
      "precision = 0.64, recall = 0.15, F1 = 0.24, accuracy = 0.79\n"
     ]
    }
   ],
   "source": [
    "cm_lr = confusion_matrix(np.where(pred_test >= how_late_is_late,1,0), predictions)\n",
    "print(\"Confusion matrix\")\n",
    "print(pd.DataFrame(cm_lr))\n",
    "\n",
    "#Get accuracy\n",
    "report_lr = precision_recall_fscore_support(\n",
    "    list(np.where(pred_test >= how_late_is_late,1,0)), \n",
    "    list(predictions), average='binary')\n",
    "\n",
    "#Print Accuracy\n",
    "print (\"\\nprecision = %0.2f, recall = %0.2f, F1 = %0.2f, accuracy = %0.2f\"\n",
    "       % (report_lr[0], report_lr[1], report_lr[2],                                                                         \n",
    "          accuracy_score(list(np.where(pred_test >= how_late_is_late,1,0)), list(predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "Relatively low precision and low recall\n",
    "Low F1 score -> bad precision and recall\n",
    "Relatively alright accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to self:\n",
    "#cross_validation -> http://scikit-learn.org/stable/modules/cross_validation.html\n",
    "#svm -> Support Vector Classification\n",
    "#ensemble ->  combine the predictions of several base estimators built with a given learning algorithm\n",
    "#in order to improve generalizability / robustness over a single estimator.\n",
    "#confusion_matrix->  evaluate the accuracy of a classification - which were correctly predicted and incorrectly predicted\n",
    "\n",
    "#precision_recall_fscore_support -> Compute precision, recall, F-measure and support for each class\n",
    "#precision -> fraction of retrieved documents that are relevant to the query\n",
    "#recall -> fraction of the relevant documents that are successfully retrieved\n",
    "\n",
    "\n",
    "#F-measure -> weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.\n",
    "#ShuffleSplit -> Random permutation cross-validation\n",
    "#RandomForestClassifier -> http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "#train_test_split -> process of spliting arrays or matrices into random train and test subsets\n",
    "#StandardScaler -> standardizes features by removing the mean and scaling to unit variance\n",
    "#OneHotEncoder -> converts features to so-called binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#The “balanced” mode uses the values of y to automatically adjust weights inversely proportional\n",
    "#to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
